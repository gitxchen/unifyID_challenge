{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Preparing the Data\n",
    "\n",
    "The sensors were sampled at 50Hz, and we want to classify at 1 second resolution, so each training example has 50 timesteps. One problem was that the 'sitting' and 'standing' activity timestamps were corrupted and all displayed the same time. However, going over the rest of the data, it was clear that most 50-sample slices were already chronologically ordered, so assuming that the sampe slices for the 'sitting' and 'standing' activities were already chronologically ordered as well is not a far stretch. Concretely, only 32 instances arise where, in a 50-sample slice, timestamp(A)>timestamp(B) when index(A)<index(B). Therefore, we assume that the samples for the 'sitting' and 'standing' activities are already chronologically ordered.\n",
    "\n",
    "We don't preprocess the features in any way, but we do add additional features - namely the magnitude of the vectors generated by each of the sensors (root of the sum of squares of the x,y, and z values). This idea was adopted from the original paper [1] that accompanied this dataset. We also experimented with using aggregate features [1] such as the mean and standard deviation values of each feature calculated over the time dimension of each 50 sample example, but we did not notice any additional performance. This is probably due to the use of batch normalization layers through out the model architecture, which would likely render the pre-normalized mean and standard deviation values somewhat useless.\n",
    "\n",
    "To create the train, val, and test sets, we split the data by activity label and perform stratified sampling to ensure a good train/val/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data\n",
      "skipped 1302 samples\n",
      "Standing examples: train 1521 val 217 test 434\n",
      "Walking examples: train 1533 val 219 test 438\n",
      "Upstairs examples: train 1025 val 146 test 293\n",
      "Sitting examples: train 949 val 135 test 271\n",
      "Running examples: train 1549 val 221 test 442\n",
      "Downstairs examples: train 1532 val 218 test 437\n",
      "8109 training samples\n",
      "1161 val samples\n",
      "2319 test samples\n"
     ]
    }
   ],
   "source": [
    "print 'Importing data'\n",
    "data_dir = 'Activity_Recognition_DataSet/'\n",
    "sources = ['Arm','Belt','Pocket','Wrist']\n",
    "keys = { 'Standing': 0, 'Sitting': 1, 'Downstairs': 2, 'Upstairs': 3, 'Running': 4, 'Walking': 5}\n",
    "data = [ [] for i in range( len( keys ) )]\n",
    "num_classes = len(keys)\n",
    "time_steps = 50\n",
    "skipped_samples = 0\n",
    "for idx in range( len( sources ) ):\n",
    "  record = pd.read_excel( data_dir + sources[idx] + '.xlsx')\n",
    "  record.sort_values( 'Time_Stamp', inplace= True)\n",
    "  for idx2 in range( len( sources ) ):\n",
    "    record[ sources[idx2] ] = 1 if idx2 == idx else 0\n",
    "\n",
    "  record['Activity_Label'] = record['Activity_Label'].apply( lambda x: keys[x])\n",
    "  labels = record['Activity_Label']\n",
    "  record.drop(labels=['Activity_Label'], axis=1,inplace = True)\n",
    "  record['A'] = ( record['Ax']**2 + record['Ay']**2 + record['Az']**2 ) **0.5\n",
    "  record['G'] = ( record['Gx']**2 + record['Gy']**2 + record['Gz']**2 ) **0.5\n",
    "  record['M'] = ( record['Mx']**2 + record['My']**2 + record['Mz']**2 ) **0.5\n",
    "\n",
    "  for sample_idx in range(0, len(labels), time_steps):\n",
    "    if sample_idx + time_steps - 1 < len(labels):\n",
    "      time_diff = record['Time_Stamp'][sample_idx+time_steps - 1] - record['Time_Stamp'][sample_idx]\n",
    "      if time_diff <= time_steps/50.0 * 1000 \\\n",
    "          and time_diff >= 0 \\\n",
    "          and labels[sample_idx: sample_idx + time_steps].min() == labels[sample_idx: sample_idx + time_steps].max():\n",
    "        sample_x = record.iloc[sample_idx: sample_idx + time_steps]\n",
    "        data[ labels[sample_idx] ].append( ( sample_x.as_matrix(), labels[sample_idx] ) )\n",
    "      else:\n",
    "        skipped_samples = skipped_samples + 1\n",
    "    else:\n",
    "      skipped_samples = skipped_samples + 1\n",
    "\n",
    "print 'skipped ' + str(skipped_samples) + ' samples'\n",
    "\n",
    "train_set, val_set, test_set = [],[],[]\n",
    "\n",
    "for idx in range( len(data) ):\n",
    "  label_data = data[idx]\n",
    "  random.shuffle(label_data)\n",
    "  train_set.extend( label_data[0: int(0.7*len(label_data))] )\n",
    "  val_set.extend( label_data[int(0.7*len(label_data)): int(0.8*len(label_data))] )\n",
    "  test_set.extend( label_data[int(0.8*len(label_data)):] )\n",
    "\n",
    "  print keys.keys()[idx] + ' examples: train %d val %d test %d'%(int(0.7*len(label_data)),\n",
    "                                                                  int(0.1*len(label_data)),\n",
    "                                                                  int(0.2*len(label_data)))\n",
    "random.shuffle(train_set)\n",
    "random.shuffle(val_set)\n",
    "random.shuffle(test_set)\n",
    "train_X, train_Y = zip( *train_set )\n",
    "val_X, val_Y = zip( *val_set )\n",
    "test_X, test_Y = zip( *test_set )\n",
    "\n",
    "train_X, train_Y = np.stack(train_X), np.array(train_Y)\n",
    "val_X, val_Y = np.stack(val_X), np.array(val_Y)\n",
    "test_X, test_Y = np.stack(test_X), np.array(test_Y)\n",
    "\n",
    "print '%d training samples'%(train_X.shape[0])\n",
    "print '%d val samples'%(val_X.shape[0])\n",
    "print '%d test samples'%(test_X.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building the Model\n",
    "In most of the literature in this area, we see that neural network techniques come out on top relative to other classifiers. Therefore we will attempt to use more recent techniques - specifically, we will use a LSTM layer followed by two fully-connected layers. Additionally, we add batch normalization layers at the input and between the two fully-connected layers to normalize the input and hidden state. With this setup, the model achieves a test accuracy of about 87%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model\n",
      "Training\n",
      "Epoch: 0 Val acc: 0.52\n",
      "Epoch: 1 Val acc: 0.61\n",
      "Epoch: 2 Val acc: 0.65\n",
      "Epoch: 3 Val acc: 0.71\n",
      "Epoch: 4 Val acc: 0.73\n",
      "Epoch: 5 Val acc: 0.74\n",
      "Epoch: 6 Val acc: 0.79\n",
      "Epoch: 7 Val acc: 0.77\n",
      "Epoch: 8 Val acc: 0.80\n",
      "Epoch: 9 Val acc: 0.78\n",
      "Epoch: 10 Val acc: 0.82\n",
      "Epoch: 11 Val acc: 0.83\n",
      "Epoch: 12 Val acc: 0.82\n",
      "Epoch: 13 Val acc: 0.82\n",
      "Epoch: 14 Val acc: 0.85\n",
      "Epoch: 15 Val acc: 0.83\n",
      "Epoch: 16 Val acc: 0.85\n",
      "Epoch: 17 Val acc: 0.85\n",
      "Epoch: 18 Val acc: 0.84\n",
      "Epoch: 19 Val acc: 0.86\n",
      "Epoch: 20 Val acc: 0.86\n",
      "Epoch: 21 Val acc: 0.85\n",
      "Epoch: 22 Val acc: 0.86\n",
      "Epoch: 23 Val acc: 0.85\n",
      "Epoch: 24 Val acc: 0.84\n",
      "Epoch: 25 Val acc: 0.85\n",
      "Epoch: 26 Val acc: 0.86\n",
      "Epoch: 27 Val acc: 0.85\n",
      "Epoch: 28 Val acc: 0.86\n",
      "Epoch: 29 Val acc: 0.86\n",
      "Epoch: 30 Val acc: 0.86\n",
      "Epoch: 31 Val acc: 0.86\n",
      "Epoch: 32 Val acc: 0.86\n",
      "Epoch: 33 Val acc: 0.85\n",
      "Epoch: 34 Val acc: 0.86\n",
      "Epoch: 35 Val acc: 0.85\n",
      "Epoch: 36 Val acc: 0.83\n",
      "Epoch: 37 Val acc: 0.86\n",
      "Epoch: 38 Val acc: 0.86\n",
      "Epoch: 39 Val acc: 0.87\n",
      "Epoch: 40 Val acc: 0.84\n",
      "Epoch: 41 Val acc: 0.86\n",
      "Epoch: 42 Val acc: 0.86\n",
      "Epoch: 43 Val acc: 0.85\n",
      "Epoch: 44 Val acc: 0.85\n",
      "Epoch: 45 Val acc: 0.84\n",
      "Epoch: 46 Val acc: 0.82\n",
      "Epoch: 47 Val acc: 0.86\n",
      "Epoch: 48 Val acc: 0.86\n",
      "Epoch: 49 Val acc: 0.86\n",
      "Epoch: 50 Val acc: 0.86\n",
      "Epoch: 51 Val acc: 0.86\n",
      "Epoch: 52 Val acc: 0.86\n",
      "Epoch: 53 Val acc: 0.86\n",
      "Epoch: 54 Val acc: 0.85\n",
      "Epoch: 55 Val acc: 0.85\n",
      "Epoch: 56 Val acc: 0.85\n",
      "Epoch: 57 Val acc: 0.85\n",
      "Epoch: 58 Val acc: 0.86\n",
      "Epoch: 59 Val acc: 0.87\n",
      "Epoch: 60 Val acc: 0.86\n",
      "Epoch: 61 Val acc: 0.85\n",
      "Epoch: 62 Val acc: 0.86\n",
      "Epoch: 63 Val acc: 0.86\n",
      "Epoch: 64 Val acc: 0.86\n",
      "Epoch: 65 Val acc: 0.86\n",
      "Epoch: 66 Val acc: 0.86\n",
      "Epoch: 67 Val acc: 0.86\n",
      "Epoch: 68 Val acc: 0.85\n",
      "Epoch: 69 Val acc: 0.86\n",
      "Epoch: 70 Val acc: 0.85\n",
      "Epoch: 71 Val acc: 0.85\n",
      "Epoch: 72 Val acc: 0.86\n",
      "Epoch: 73 Val acc: 0.85\n",
      "Epoch: 74 Val acc: 0.86\n",
      "Epoch: 75 Val acc: 0.85\n",
      "Epoch: 76 Val acc: 0.86\n",
      "Epoch: 77 Val acc: 0.85\n",
      "Epoch: 78 Val acc: 0.82\n",
      "Epoch: 79 Val acc: 0.83\n",
      "Epoch: 80 Val acc: 0.86\n",
      "Epoch: 81 Val acc: 0.85\n",
      "Epoch: 82 Val acc: 0.86\n",
      "Epoch: 83 Val acc: 0.87\n",
      "Epoch: 84 Val acc: 0.86\n",
      "Epoch: 85 Val acc: 0.86\n",
      "Epoch: 86 Val acc: 0.86\n",
      "Epoch: 87 Val acc: 0.86\n",
      "Epoch: 88 Val acc: 0.87\n",
      "Epoch: 89 Val acc: 0.86\n",
      "Epoch: 90 Val acc: 0.86\n",
      "Epoch: 91 Val acc: 0.87\n",
      "Epoch: 92 Val acc: 0.85\n",
      "Epoch: 93 Val acc: 0.84\n",
      "Epoch: 94 Val acc: 0.86\n",
      "Epoch: 95 Val acc: 0.86\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6bdd0bd54c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0minX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minY\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'Epoch: %d Val acc: %.2f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_Y\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;32mprint\u001b[0m \u001b[0;34m'Test acc: %.2f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \"\"\"\n\u001b[0;32m-> 1449\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3666\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3667\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3668\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print 'Building Model'\n",
    "input_var = tf.placeholder(tf.float32, shape = [None,time_steps,train_X.shape[2]-1])\n",
    "true_labels = tf.placeholder(tf.int32)\n",
    "learning_rate = 0.05\n",
    "lstm_dim = 100\n",
    "\n",
    "with tf.variable_scope('lstm') as scope:\n",
    "  lstm_cell = tf.nn.rnn_cell.LSTMCell(lstm_dim)\n",
    "  rnn_output, _ = tf.nn.dynamic_rnn(lstm_cell, tf.contrib.layers.batch_norm(input_var), dtype = tf.float32)\n",
    "  rnn_output = rnn_output[:, -1]\n",
    "  rnn_output = tf.contrib.layers.batch_norm( rnn_output )\n",
    "\n",
    "with tf.variable_scope('fc_1') as scope:\n",
    "  fc_w = tf.get_variable('fc_w', shape = [lstm_dim, lstm_dim] )\n",
    "  fc_b = tf.get_variable('fc_b', shape = [lstm_dim] )\n",
    "  fc_1 = tf.add( tf.matmul( rnn_output, fc_w), fc_b)\n",
    "  fc_1 = tf.nn.relu(fc_1)\n",
    "  fc_1_bn = tf.contrib.layers.batch_norm(fc_1)\n",
    "\n",
    "with tf.variable_scope('fc_2') as scope:\n",
    "  fc_w = tf.get_variable('fc_w', shape = [lstm_dim, num_classes])\n",
    "  fc_b = tf.get_variable('fc_b', shape = [num_classes] )\n",
    "  output = tf.add( tf.matmul( fc_1_bn, fc_w), fc_b)\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(output,true_labels))\n",
    "train_step = tf.train.AdadeltaOptimizer(learning_rate).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.to_int32(tf.argmax( output, 1)), true_labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print 'Training'\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  for epoch in range(200):\n",
    "    for batch_idx in range(0,train_X.shape[0], 50):\n",
    "      inX = train_X[batch_idx: batch_idx + 50] if batch_idx + 50 < train_X.shape[0] else train_X[batch_idx:]\n",
    "      inY = train_Y[batch_idx: batch_idx + 50] if batch_idx + 50 < train_Y.shape[0] else train_Y[batch_idx:]\n",
    "      inX = inX[:,:,1:]\n",
    "\n",
    "      train_step.run( feed_dict = {input_var: inX, true_labels: inY} )\n",
    "    print 'Epoch: %d Val acc: %.2f'%(epoch, accuracy.eval( feed_dict = {input_var: val_X[:,:,1:], true_labels: val_Y} ) )\n",
    "  print 'Test acc: %.2f'%(accuracy.eval( feed_dict = {input_var: test_X[:,:,1:], true_labels: test_Y} ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "    [1] Shoaib, M.; Scholten, H.; Havinga, P.J.M.; Towards Physical Activity Recognition Using Smartphone Sensors.         Ubiquitous Intelligence and Computing, 2013 IEEE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
