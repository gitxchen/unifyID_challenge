{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Preparing the Data\n",
    "\n",
    "The sensors were sampled at 50Hz, and we want to classify at 1 second resolution, so each training example has 50 timesteps. One problem was that the 'sitting' and 'standing' activity timestamps were corrupted and all displayed the same time. However, going over the rest of the data, it was clear that most 50-sample slices were already chronologically ordered, so assuming that the sampe slices for the 'sitting' and 'standing' activities were already chronologically ordered as well is not a far stretch. Concretely, only 32 instances arise where, in a 50-sample slice, timestamp(A)>timestamp(B) when index(A)<index(B). Therefore, we assume that the samples for the 'sitting' and 'standing' activities are already chronologically ordered.\n",
    "\n",
    "We don't preprocess the features in any way, but we do add additional features - namely the magnitude of the vectors generated by each of the sensors (root of the sum of squares of the x,y, and z values). This idea was adopted from the original paper [1] that accompanied this dataset. We also experimented with using aggregate features [1] such as the mean and standard deviation values of each feature calculated over the time dimension of each 50 sample example, but we did not notice any additional performance. This is probably due to the use of batch normalization layers through out the model architecture, which would likely render the pre-normalized mean and standard deviation values somewhat useless.\n",
    "\n",
    "To create the train, val, and test sets, we split the data by activity label and perform stratified sampling to ensure a good train/val/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print 'Importing data'\n",
    "data_dir = 'Activity_Recognition_DataSet/'\n",
    "sources = ['Arm','Belt','Pocket','Wrist']\n",
    "keys = { 'Standing': 0, 'Sitting': 1, 'Downstairs': 2, 'Upstairs': 3, 'Running': 4, 'Walking': 5}\n",
    "data = [ [] for i in range( len( keys ) )]\n",
    "num_classes = len(keys)\n",
    "time_steps = 50\n",
    "skipped_samples = 0\n",
    "for idx in range( len( sources ) ):\n",
    "  record = pd.read_excel( data_dir + sources[idx] + '.xlsx')\n",
    "  record.sort_values( 'Time_Stamp', inplace= True)\n",
    "  for idx2 in range( len( sources ) ):\n",
    "    record[ sources[idx2] ] = 1 if idx2 == idx else 0\n",
    "\n",
    "  record['Activity_Label'] = record['Activity_Label'].apply( lambda x: keys[x])\n",
    "  labels = record['Activity_Label']\n",
    "  record.drop(labels=['Activity_Label'], axis=1,inplace = True)\n",
    "  record['A'] = ( record['Ax']**2 + record['Ay']**2 + record['Az']**2 ) **0.5\n",
    "  record['G'] = ( record['Gx']**2 + record['Gy']**2 + record['Gz']**2 ) **0.5\n",
    "  record['M'] = ( record['Mx']**2 + record['My']**2 + record['Mz']**2 ) **0.5\n",
    "\n",
    "  for sample_idx in range(0, len(labels), time_steps):\n",
    "    if sample_idx + time_steps - 1 < len(labels):\n",
    "      time_diff = record['Time_Stamp'][sample_idx+time_steps - 1] - record['Time_Stamp'][sample_idx]\n",
    "      if time_diff <= time_steps/50.0 * 1000 \\\n",
    "          and time_diff >= 0 \\\n",
    "          and labels[sample_idx: sample_idx + time_steps].min() == labels[sample_idx: sample_idx + time_steps].max():\n",
    "        sample_x = record.iloc[sample_idx: sample_idx + time_steps]\n",
    "        data[ labels[sample_idx] ].append( ( sample_x.as_matrix(), labels[sample_idx] ) )\n",
    "      else:\n",
    "        skipped_samples = skipped_samples + 1\n",
    "    else:\n",
    "      skipped_samples = skipped_samples + 1\n",
    "\n",
    "print 'skipped ' + str(skipped_samples) + ' samples'\n",
    "\n",
    "train_set, val_set, test_set = [],[],[]\n",
    "\n",
    "for idx in range( len(data) ):\n",
    "  label_data = data[idx]\n",
    "  random.shuffle(label_data)\n",
    "  train_set.extend( label_data[0: int(0.7*len(label_data))] )\n",
    "  val_set.extend( label_data[int(0.7*len(label_data)): int(0.8*len(label_data))] )\n",
    "  test_set.extend( label_data[int(0.8*len(label_data)):] )\n",
    "\n",
    "  print keys.keys()[idx] + ' examples: train %d val %d test %d'%(int(0.7*len(label_data)),\n",
    "                                                                  int(0.1*len(label_data)),\n",
    "                                                                  int(0.2*len(label_data)))\n",
    "random.shuffle(train_set)\n",
    "random.shuffle(val_set)\n",
    "random.shuffle(test_set)\n",
    "train_X, train_Y = zip( *train_set )\n",
    "val_X, val_Y = zip( *val_set )\n",
    "test_X, test_Y = zip( *test_set )\n",
    "\n",
    "train_X, train_Y = np.stack(train_X), np.array(train_Y)\n",
    "val_X, val_Y = np.stack(val_X), np.array(val_Y)\n",
    "test_X, test_Y = np.stack(test_X), np.array(test_Y)\n",
    "\n",
    "print '%d training samples'%(train_X.shape[0])\n",
    "print '%d val samples'%(val_X.shape[0])\n",
    "print '%d test samples'%(test_X.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building the Model\n",
    "In most of the literature in this area, we see that neural network techniques come out on top relative to other classifiers. Therefore we will attempt to use more recent techniques - specifically, we will use a LSTM layer followed by two fully-connected layers. Additionally, we add batch normalization layers at the input and between the two fully-connected layers to normalize the input and hidden state. With this setup, the model achieves a test accuracy of about 87%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print 'Building Model'\n",
    "input_var = tf.placeholder(tf.float32, shape = [None,time_steps,train_X.shape[2]-1])\n",
    "true_labels = tf.placeholder(tf.int32)\n",
    "learning_rate = 0.05\n",
    "lstm_dim = 100\n",
    "\n",
    "with tf.variable_scope('lstm') as scope:\n",
    "  lstm_cell = tf.nn.rnn_cell.LSTMCell(lstm_dim)\n",
    "  rnn_output, _ = tf.nn.dynamic_rnn(lstm_cell, tf.contrib.layers.batch_norm(input_var), dtype = tf.float32)\n",
    "  rnn_output = rnn_output[:, -1]\n",
    "  rnn_output = tf.contrib.layers.batch_norm( rnn_output )\n",
    "\n",
    "with tf.variable_scope('fc_1') as scope:\n",
    "  fc_w = tf.get_variable('fc_w', shape = [lstm_dim, lstm_dim] )\n",
    "  fc_b = tf.get_variable('fc_b', shape = [lstm_dim] )\n",
    "  fc_1 = tf.add( tf.matmul( rnn_output, fc_w), fc_b)\n",
    "  fc_1 = tf.nn.relu(fc_1)\n",
    "  fc_1_bn = tf.contrib.layers.batch_norm(fc_1)\n",
    "\n",
    "with tf.variable_scope('fc_2') as scope:\n",
    "  fc_w = tf.get_variable('fc_w', shape = [lstm_dim, num_classes])\n",
    "  fc_b = tf.get_variable('fc_b', shape = [num_classes] )\n",
    "  output = tf.add( tf.matmul( fc_1_bn, fc_w), fc_b)\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(output,true_labels))\n",
    "train_step = tf.train.AdadeltaOptimizer(learning_rate).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.to_int32(tf.argmax( output, 1)), true_labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print 'Training'\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  for epoch in range(200):\n",
    "    for batch_idx in range(0,train_X.shape[0], 50):\n",
    "      inX = train_X[batch_idx: batch_idx + 50] if batch_idx + 50 < train_X.shape[0] else train_X[batch_idx:]\n",
    "      inY = train_Y[batch_idx: batch_idx + 50] if batch_idx + 50 < train_Y.shape[0] else train_Y[batch_idx:]\n",
    "      inX = inX[:,:,1:]\n",
    "\n",
    "      train_step.run( feed_dict = {input_var: inX, true_labels: inY} )\n",
    "    print 'Epoch: %d Val acc: %.2f'%(epoch, accuracy.eval( feed_dict = {input_var: val_X[:,:,1:], true_labels: val_Y} ) )\n",
    "  print 'Test acc: %.2f'%(accuracy.eval( feed_dict = {input_var: test_X[:,:,1:], true_labels: test_Y} ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "References:\n",
    "    [1] Shoaib, M.; Scholten, H.; Havinga, P.J.M.; Towards Physical Activity Recognition Using Smartphone Sensors.         Ubiquitous Intelligence and Computing, 2013 IEEE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
